{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch MNIST\n",
    "\n",
    "References:\n",
    "- [https://nextjournal.com/gkoehler/pytorch-mnist](https://nextjournal.com/gkoehler/pytorch-mnist)\n",
    "- [https://www.youtube.com/watch?v=Vs730jsRgO8](https://www.youtube.com/watch?v=Vs730jsRgO8)\n",
    "\n",
    "TODO:\n",
    "- Refactor\n",
    "- Understand model inputs/ outputs\n",
    "- data augmentation\n",
    "- ONNX\n",
    "- ONNX Js\n",
    "- Retrain with new data?\n",
    "\n",
    "https://onnx.ai/\n",
    "https://github.com/microsoft/onnxruntime/tree/main/js/web#readme  \n",
    "https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html  \n",
    "https://pytorch.org/tutorials/beginner/introyt.html  \n",
    "https://pytorch.org/tutorials/beginner/pytorch_with_examples.html  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10431dcd0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 3\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transformer = torchvision.transforms.Compose([\n",
    "\ttorchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST('data/', train=True, download=True, transform=transformer)\n",
    "test_dataset = torchvision.datasets.MNIST('data/', train=False, download=True, transform=transformer)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size_train, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 1, 28, 28]), torch.Size([1000]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_features, example_labels) = next(examples)\n",
    "example_features.shape, example_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "for index in range(6):\n",
    "\tplt.subplot(2 ,3 , index + 1)\n",
    "\tplt.tight_layout()\n",
    "\n",
    "\tplt.imshow(example_features[index][0], cmap='gray')\n",
    "\tplt.title(f'Label: {example_labels[index]}', color='#1E90FF')\n",
    "\n",
    "\tplt.xticks([])\n",
    "\tplt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class Net(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(Net, self).__init__()\n",
    "\t\tself.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "\t\tself.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "\t\tself.conv2_drop = nn.Dropout2d()\n",
    "\n",
    "\t\tself.fc1 = nn.Linear(50, 10)\n",
    "\t\tself.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = F.max_pool2d(self.conv1(x), 2)\n",
    "\t\tx = F.relu(x)\n",
    "\n",
    "\t\t# x = self.conv2_drop(x)\n",
    "\t\tx = F.max_pool2d(self.conv2(x), 2)\n",
    "\t\tx = F.relu(x)\n",
    "\n",
    "\t\tx = x.view(-1, 320)\n",
    "\n",
    "\t\tx = self.fc1(x)\n",
    "\t\tx = F.relu(x)\n",
    "\t\tx = F.dropout(x, training=self.training)\n",
    "\t\tx = self.fc2(x)\n",
    "\n",
    "\t\treturn F.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(Net, self).__init__()\n",
    "\t\tself.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "\t\tself.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "\t\tself.conv2_drop = nn.Dropout2d()\n",
    "\t\tself.fc1 = nn.Linear(320, 50)\n",
    "\t\tself.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "\t\tx = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "\t\tx = x.view(-1, 320)\n",
    "\t\tx = F.relu(self.fc1(x))\n",
    "\t\tx = F.dropout(x, training=self.training)\n",
    "\t\tx = self.fc2(x)\n",
    "\t\treturn F.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Net()\n",
    "\n",
    "optimizer = optim.SGD(\n",
    "\tnetwork.parameters(),\n",
    "\tlr=learning_rate,\n",
    "\tmomentum=momentum\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "\tnetwork.train()\n",
    "\n",
    "\tfor batch_idx, (data, target) in enumerate(train_loader):\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\toutput = network(data)\n",
    "\t\tloss = F.nll_loss(output, target)\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\n",
    "\t\tif batch_idx % log_interval == 0:\n",
    "\t\t\tprint('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "\t\t\t\tepoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "\t\t\t\t100. * batch_idx / len(train_loader), loss.item())\n",
    "\t\t\t)\n",
    "\n",
    "\t\t\ttrain_losses.append(loss.item())\n",
    "\t\t\ttrain_counter.append((batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "\t\t\ttorch.save(network.state_dict(), 'output/model.pth')\n",
    "\t\t\ttorch.save(optimizer.state_dict(), 'output/optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "\tnetwork.eval()\n",
    "\ttest_loss = 0\n",
    "\tcorrect = 0\n",
    "\n",
    "\twith torch.no_grad():\n",
    "\t\tfor data, target in test_loader:\n",
    "\t\t\toutput = network(data)\n",
    "\t\t\ttest_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "\t\t\tpred = output.data.max(1, keepdim=True)[1]\n",
    "\t\t\tcorrect += pred.eq(target.data.view_as(pred)).sum()\n",
    "\n",
    "\ttest_loss /= len(test_loader.dataset)\n",
    "\ttest_losses.append(test_loss)\n",
    "\n",
    "\taccuracy_percentage = 100 * correct / len(test_loader.dataset)\n",
    "\tprint(f'\\nTest set: Avg. loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy_percentage:.0f}%)\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9f/ns03tkgj6p55j2qf18sdwkdr0000gn/T/ipykernel_80159/1786143091.py:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (640) to match target batch_size (1000).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/marc/Development/ionine/mnist-client/python/example.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/marc/Development/ionine/mnist-client/python/example.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m test()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/marc/Development/ionine/mnist-client/python/example.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, n_epochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/marc/Development/ionine/mnist-client/python/example.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \ttrain(epoch)\n",
      "\u001b[1;32m/Users/marc/Development/ionine/mnist-client/python/example.ipynb Cell 17\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/marc/Development/ionine/mnist-client/python/example.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m data, target \u001b[39min\u001b[39;00m test_loader:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/marc/Development/ionine/mnist-client/python/example.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \toutput \u001b[39m=\u001b[39m network(data)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/marc/Development/ionine/mnist-client/python/example.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \ttest_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mnll_loss(output, target, size_average\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/marc/Development/ionine/mnist-client/python/example.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \tpred \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mmax(\u001b[39m1\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/marc/Development/ionine/mnist-client/python/example.ipynb#X26sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \tcorrect \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m pred\u001b[39m.\u001b[39meq(target\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mview_as(pred))\u001b[39m.\u001b[39msum()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/torch/nn/functional.py:2689\u001b[0m, in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2687\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2688\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 2689\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mnll_loss_nd(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index)\n",
      "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (640) to match target batch_size (1000)."
     ]
    }
   ],
   "source": [
    "test()\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "\ttrain(epoch)\n",
    "\ttest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(train_counter, train_losses, color='blue')\n",
    "plt.scatter(test_counter, test_losses, color='red')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "\toutput = network(example_data)\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "for i in range(6):\n",
    "\tplt.subplot(2,3,i+1)\n",
    "\tplt.tight_layout()\n",
    "\tplt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "\tplt.title(\"Prediction: {}\".format(output.data.max(1, keepdim=True)[1][i].item()), color='white')\n",
    "\tplt.xticks([])\n",
    "\tplt.yticks([])\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continued_network = Net()\n",
    "\n",
    "continued_optimizer = optim.SGD(\n",
    "\tnetwork.parameters(),\n",
    "\tlr=learning_rate,\n",
    "\tmomentum=momentum,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_state_dict = torch.load('output/model.pth')\n",
    "continued_network.load_state_dict(network_state_dict)\n",
    "\n",
    "optimizer_state_dict = torch.load('output/optimizer.pth')\n",
    "continued_optimizer.load_state_dict(optimizer_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4,9):\n",
    "\ttest_counter.append(i*len(train_loader.dataset))\n",
    "\ttrain(i)\n",
    "\ttest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(train_counter, train_losses, color='blue')\n",
    "plt.scatter(test_counter, test_losses, color='red')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(network.state_dict(), 'output/model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_model = Net()\n",
    "pt_model.load_state_dict(torch.load('output/model.pt'))\n",
    "pt_model.eval()\n",
    "\n",
    "dummy_input = torch.zeros(1, 1, 28, 28)\n",
    "torch.onnx.export(pt_model, dummy_input, 'onnx_model.onnx', verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
